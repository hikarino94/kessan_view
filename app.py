"""KessanView - æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ«

ã‚·ãƒ³ã‚°ãƒ«ãƒšãƒ¼ã‚¸æ§‹æˆã®Streamlitã‚¢ãƒ—ãƒªã€‚
å·¦å³2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨è©³ç´°ã‚’åŒæ™‚é–²è¦§å¯èƒ½ã€‚
"""
import json
import logging
import re
import sys
from datetime import date, datetime, timedelta
from pathlib import Path

import pandas as pd
import plotly.graph_objects as go
import streamlit as st

# ãƒ‘ã‚¹è¨­å®š
sys.path.insert(0, str(Path(__file__).resolve().parent))

import config
from db.database import get_session, init_db
from models.schemas import (
    AIAnalysisResult,
    DailyPrice,
    EarningsScore,
    FinancialStatement,
    Stock,
    TDnetDisclosure,
)
from services.financial_analysis import FinancialAnalyzer
from services.scoring import ScoringService

# â”€â”€ ãƒ­ã‚°è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# â”€â”€ ãƒšãƒ¼ã‚¸è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="KessanView - æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# â”€â”€ ã‚«ã‚¹ã‚¿ãƒ CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
    .main .block-container {
        padding-top: 0.5rem;
        max-width: 1600px;
    }
    div[data-testid="stMetric"] {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-radius: 10px;
        padding: 10px;
        border-left: 3px solid #667eea;
    }
    .section-header {
        background: linear-gradient(90deg, #667eea, #764ba2);
        color: white;
        padding: 6px 14px;
        border-radius: 8px;
        margin: 8px 0 6px 0;
        font-size: 16px;
        font-weight: bold;
    }
    /* ãƒ©ãƒ³ã‚­ãƒ³ã‚°é¸æŠè¡Œã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ */
    .selected-stock {
        background: #e8f0fe;
        border-radius: 6px;
        padding: 4px 8px;
        margin: 4px 0;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ DBåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
init_db()

# â”€â”€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "selected_code" not in st.session_state:
    st.session_state.selected_code = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def get_forecast_progress_batch(codes: list, dt) -> dict:
    """è¤‡æ•°éŠ˜æŸ„ã®é€šæœŸäºˆæƒ³é€²æ—ç‡ã‚’ä¸€æ‹¬å–å¾—"""
    session = get_session()
    try:
        stmts = (
            session.query(FinancialStatement)
            .filter(FinancialStatement.code.in_(codes), FinancialStatement.disclosed_date == dt)
            .all()
        )
        results = {}
        for stmt in stmts:
            period = stmt.type_of_current_period or ""
            standard = {"1Q": 25, "2Q": 50, "3Q": 75, "FY": 100}.get(period, 0)
            prog = {}
            for label, af, ff in [
                ("å£²ä¸Š", "net_sales", "forecast_net_sales"),
                ("å–¶åˆ©", "operating_profit", "forecast_operating_profit"),
                ("ç´”åˆ©", "profit", "forecast_profit"),
            ]:
                actual = getattr(stmt, af, None)
                forecast = getattr(stmt, ff, None)
                if actual is not None and forecast and forecast != 0:
                    prog[label] = round(actual / forecast * 100, 1)
            results[stmt.code] = {"period": period, "standard": standard, **prog}
        return results
    finally:
        session.close()


def get_tdnet_map(dt) -> dict:
    """å¯¾è±¡æ—¥ã®TDneté–‹ç¤ºæƒ…å ±ã‚’codeâ†’docè¾æ›¸ã§ä¸€æ‹¬å–å¾—"""
    session = get_session()
    try:
        docs = (
            session.query(TDnetDisclosure)
            .filter(TDnetDisclosure.disclosed_date == dt, TDnetDisclosure.is_earnings_report == 1)
            .all()
        )
        result = {}
        for d in docs:
            if d.code:
                result[d.code] = {
                    "document_url": d.document_url or "",
                    "pdf_local_path": d.pdf_local_path or "",
                    "company_name": d.company_name or "",
                    "title": d.title or "",
                }
        return result
    finally:
        session.close()


def run_single_ai_analysis(code: str, dt_str: str):
    """å˜ä¸€éŠ˜æŸ„ã®AIåˆ†æã‚’å®Ÿè¡Œ"""
    from services.ai_analyzer import AIAnalyzer
    session = get_session()
    try:
        disclosure = (
            session.query(TDnetDisclosure)
            .filter(
                TDnetDisclosure.code == code,
                TDnetDisclosure.disclosed_date == datetime.strptime(dt_str, "%Y-%m-%d").date(),
                TDnetDisclosure.is_earnings_report == 1,
            )
            .first()
        )
        if not disclosure or not disclosure.pdf_local_path:
            return {"is_error": True, "error": "PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        pdf_path = disclosure.pdf_local_path
        company_name = disclosure.company_name or ""
    finally:
        session.close()

    analyzer = AIAnalyzer()
    return analyzer.analyze_and_save(
        pdf_path=pdf_path, code=code, disclosed_date=dt_str,
        disclosure_number="", company_name=company_name,
    )


def parse_ai_display(ai_result) -> dict:
    """AIåˆ†æçµæœã‚’è¡¨ç¤ºç”¨ã«æ•´å½¢ã€‚å£Šã‚ŒãŸJSONä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚‚ãƒªã‚«ãƒãƒª"""
    summary_text = ai_result.summary or ""

    if summary_text.startswith("åˆ†æã‚¨ãƒ©ãƒ¼:"):
        return {"is_error": True, "error": summary_text}

    display = {"summary": summary_text, "key_points": [], "keywords": [],
               "signal_words": [], "sentiment": ai_result.sentiment or "neutral"}

    if summary_text.lstrip().startswith(("{", "```")):
        # JSONãŒç›´æ¥summaryã«æ ¼ç´ã•ã‚ŒãŸã‚±ãƒ¼ã‚¹ã®ãƒªã‚«ãƒãƒª
        fence_m = re.search(r'```(?:json)?\s*\n?(\{.*)', summary_text, re.DOTALL)
        json_candidate = fence_m.group(1).rstrip('`').strip() if fence_m else summary_text.strip().lstrip('`').strip()
        if json_candidate.count("{") > json_candidate.count("}"):
            json_candidate += "}" * (json_candidate.count("{") - json_candidate.count("}"))
        try:
            parsed = json.loads(json_candidate)
            display["summary"] = parsed.get("summary", summary_text[:300])
            display["key_points"] = parsed.get("key_points", [])
            display["keywords"] = parsed.get("keywords", [])
            display["signal_words"] = parsed.get("signal_words", [])
            display["sentiment"] = parsed.get("sentiment", display["sentiment"])
        except (json.JSONDecodeError, AttributeError):
            sum_m = re.search(r'"summary"\s*:\s*"([^"]*)"', summary_text)
            if sum_m:
                display["summary"] = sum_m.group(1)
    else:
        # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿
        for field, key in [("key_points", "key_points"), ("keywords", "keywords"), ("signal_words", "signal_words")]:
            raw = getattr(ai_result, field, None)
            if raw:
                try:
                    display[key] = json.loads(raw)
                except json.JSONDecodeError:
                    pass

    display["is_error"] = False
    return display


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    st.subheader("ğŸ“… å¯¾è±¡æ—¥ä»˜")
    try:
        default_date = datetime.strptime(config.DEV_TEST_DATE, "%Y-%m-%d").date()
    except Exception:
        default_date = date.today()

    target_date = st.date_input("åˆ†æå¯¾è±¡æ—¥", value=default_date)
    target_date_str = target_date.strftime("%Y-%m-%d")

    st.divider()
    st.subheader("ğŸ”‘ APIè¨­å®š")
    st.caption(f"J-Quants: {'âœ…' if config.JQUANTS_API_KEY else 'âŒ'} | Gemini: {'âœ…' if config.GEMINI_API_KEY else 'âŒ'}")

    st.divider()
    st.subheader("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é‡ã¿")
    w = dict(config.DEFAULT_SCORING_WEIGHTS)
    w["yoy_sales"] = st.slider("å£²ä¸Šé«˜YoY", 0.0, 1.0, w["yoy_sales"], 0.05)
    w["yoy_operating_income"] = st.slider("å–¶æ¥­åˆ©ç›ŠYoY", 0.0, 1.0, w["yoy_operating_income"], 0.05)
    w["yoy_profit"] = st.slider("ç´”åˆ©ç›ŠYoY", 0.0, 1.0, w["yoy_profit"], 0.05)
    w["qoq_acceleration"] = st.slider("QoQåŠ é€Ÿåº¦", 0.0, 1.0, w["qoq_acceleration"], 0.05)
    w["revision_flag"] = st.slider("æ¥­ç¸¾ä¿®æ­£", 0.0, 1.0, w["revision_flag"], 0.05)
    w["turnaround_flag"] = st.slider("èµ¤é»’è»¢æ›", 0.0, 1.0, w["turnaround_flag"], 0.05)
    total_w = sum(w.values())
    if total_w > 0:
        w = {k: v / total_w for k, v in w.items()}

    st.divider()
    st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿åŒæœŸ")
    sync_type = st.selectbox("åŒæœŸã‚¿ã‚¤ãƒ—", ["éŠ˜æŸ„ãƒã‚¹ã‚¿", "æ±ºç®—æƒ…å ± (æ—¥ä»˜æŒ‡å®š)", "æ ªä¾¡ (æ—¥ä»˜æŒ‡å®š)", "TDneté–‹ç¤ºæƒ…å ±", "å…¨ã¦"])

    if st.button("â–¶ï¸ åŒæœŸå®Ÿè¡Œ", type="primary", use_container_width=True):
        try:
            if sync_type in ["éŠ˜æŸ„ãƒã‚¹ã‚¿", "å…¨ã¦"]:
                from services.sync import SyncService
                with st.spinner("éŠ˜æŸ„ãƒã‚¹ã‚¿åŒæœŸä¸­..."):
                    st.success(f"éŠ˜æŸ„ãƒã‚¹ã‚¿: {SyncService().sync_listed_info()}ä»¶åŒæœŸå®Œäº†")
            if sync_type in ["æ±ºç®—æƒ…å ± (æ—¥ä»˜æŒ‡å®š)", "å…¨ã¦"]:
                from services.sync import SyncService
                with st.spinner(f"æ±ºç®—æƒ…å ±åŒæœŸä¸­... ({target_date_str})"):
                    st.success(f"æ±ºç®—æƒ…å ±: {SyncService().sync_statements_by_date(target_date_str)}ä»¶åŒæœŸå®Œäº†")
            if sync_type in ["æ ªä¾¡ (æ—¥ä»˜æŒ‡å®š)", "å…¨ã¦"]:
                from services.sync import SyncService
                with st.spinner(f"æ ªä¾¡åŒæœŸä¸­... ({target_date_str})"):
                    st.success(f"æ ªä¾¡: {SyncService().sync_daily_prices_by_date(target_date_str)}ä»¶åŒæœŸå®Œäº†")
            if sync_type in ["TDneté–‹ç¤ºæƒ…å ±", "å…¨ã¦"]:
                from services.tdnet import TDnetClient
                tdnet = TDnetClient()
                with st.spinner(f"TDnetåŒæœŸä¸­... ({target_date_str})"):
                    disclosures = tdnet.get_disclosures_by_date(target_date_str)
                    st.success(f"TDnet: {tdnet.save_disclosures_to_db(disclosures, target_date_str)}ä»¶åŒæœŸå®Œäº†")
        except Exception as e:
            st.error(f"åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ“¥ æ±ºç®—çŸ­ä¿¡PDFä¸€æ‹¬DL", use_container_width=True):
        try:
            from services.tdnet import TDnetClient
            with st.spinner(f"PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                results = TDnetClient().download_all_earnings_pdfs(target_date_str)
                st.success(f"PDF: {sum(1 for r in results if r['success'])}/{len(results)}ä»¶DLå®Œäº†")
        except Exception as e:
            st.error(f"PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ¤– AIåˆ†æä¸€æ‹¬å®Ÿè¡Œ", use_container_width=True):
        try:
            from services.ai_analyzer import AIAnalyzer
            analyzer = AIAnalyzer()
            session = get_session()
            try:
                dt_tmp = datetime.strptime(target_date_str, "%Y-%m-%d").date()
                items = [
                    {"pdf_path": d.pdf_local_path, "code": d.code,
                     "disclosed_date": target_date_str, "company_name": d.company_name}
                    for d in session.query(TDnetDisclosure).filter(
                        TDnetDisclosure.disclosed_date == dt_tmp,
                        TDnetDisclosure.is_earnings_report == 1,
                        TDnetDisclosure.pdf_local_path != "",
                    ).all()
                ]
            finally:
                session.close()
            if items:
                pb = st.progress(0, text="AIåˆ†æä¸­...")
                results = analyzer.batch_analyze(items, progress_callback=lambda c, t: pb.progress(c / t, text=f"AIåˆ†æä¸­... {c}/{t}"))
                st.success(f"AIåˆ†æ: {sum(1 for r in results if r.get('success'))}/{len(results)}ä»¶å®Œäº†")
            else:
                st.warning("åˆ†æå¯¾è±¡ã®PDFãŒã‚ã‚Šã¾ã›ã‚“")
        except Exception as e:
            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œ", use_container_width=True):
        try:
            with st.spinner("ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­..."):
                results = ScoringService(weights=w).score_all_for_date(target_date_str)
                st.success(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: {len(results)}ä»¶å®Œäº†")
                st.rerun()
        except Exception as e:
            st.error(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ˜ãƒƒãƒ€ãƒ¼ + ã‚µãƒãƒªãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown(f"## ğŸ“Š KessanView â€” {target_date_str}")

dt = datetime.strptime(target_date_str, "%Y-%m-%d").date()

session = get_session()
try:
    total_statements = session.query(FinancialStatement).filter(FinancialStatement.disclosed_date == dt).count()
    total_scores = session.query(EarningsScore).filter(EarningsScore.disclosed_date == dt).count()
    attention_count = session.query(EarningsScore).filter(EarningsScore.disclosed_date == dt, EarningsScore.category == "æ³¨ç›®").count()
    check_count = session.query(EarningsScore).filter(EarningsScore.disclosed_date == dt, EarningsScore.category == "è¦ç¢ºèª").count()
    ai_count = session.query(AIAnalysisResult).filter(AIAnalysisResult.disclosed_date == dt).count()
    tdnet_count = session.query(TDnetDisclosure).filter(TDnetDisclosure.disclosed_date == dt, TDnetDisclosure.is_earnings_report == 1).count()
finally:
    session.close()

mc = st.columns(6)
mc[0].metric("ğŸ“‹ æ±ºç®—", f"{total_statements}ä»¶")
mc[1].metric("ğŸ† æ³¨ç›®", f"{attention_count}ä»¶")
mc[2].metric("ğŸ‘ï¸ è¦ç¢ºèª", f"{check_count}ä»¶")
mc[3].metric("ğŸ“„ TDnet", f"{tdnet_count}ä»¶")
mc[4].metric("ğŸ¤– AIæ¸ˆ", f"{ai_count}ä»¶")
mc[5].metric("ğŸ“Š ã‚¹ã‚³ã‚¢", f"{total_scores}ä»¶")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬å–å¾—
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
tdnet_map = get_tdnet_map(dt)

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°/ä¸€è¦§ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
ranking_rows = []
ranking_codes = []

if total_scores > 0:
    session = get_session()
    try:
        scores_data = (
            session.query(EarningsScore, Stock.name, Stock.sector_33_name)
            .outerjoin(Stock, EarningsScore.code == Stock.code)
            .filter(EarningsScore.disclosed_date == dt)
            .order_by(EarningsScore.total_score.desc())
            .all()
        )
    finally:
        session.close()

    all_codes = [s.code for s, _, _ in scores_data]
    progress_map = get_forecast_progress_batch(all_codes, dt)

    for score, name, sector in scores_data:
        prog = progress_map.get(score.code, {})
        prog_profit = prog.get("ç´”åˆ©")
        tdoc = tdnet_map.get(score.code, {})
        ranking_rows.append({
            "score": round(score.total_score, 1),
            "category": score.category or "é€šå¸¸",
            "code": score.code,
            "name": name or "",
            "sector": (sector or "")[:6],
            "yoy_sales": f"{score.yoy_sales_change:+.1f}" if score.yoy_sales_change is not None else "-",
            "yoy_op": f"{score.yoy_op_change:+.1f}" if score.yoy_op_change is not None else "-",
            "yoy_profit": f"{score.yoy_profit_change:+.1f}" if score.yoy_profit_change is not None else "-",
            "progress": f"{prog_profit:.0f}" if prog_profit is not None else "-",
            "pdf": "âœ…" if tdoc.get("pdf_local_path") and Path(tdoc["pdf_local_path"]).exists() else "",
        })
        ranking_codes.append(score.code)
elif tdnet_count > 0:
    # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æœªå®Ÿæ–½: TDnetãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    for code, info in sorted(tdnet_map.items()):
        ranking_rows.append({
            "score": "-",
            "category": "-",
            "code": code,
            "name": info["company_name"] or "",
            "sector": "",
            "yoy_sales": "-",
            "yoy_op": "-",
            "yoy_profit": "-",
            "progress": "-",
            "pdf": "âœ…" if info["pdf_local_path"] and Path(info["pdf_local_path"]).exists() else "",
        })
        ranking_codes.append(code)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: å·¦=ãƒ©ãƒ³ã‚­ãƒ³ã‚° / å³=è©³ç´°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
left_col, right_col = st.columns([2, 3], gap="medium")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å·¦ã‚«ãƒ©ãƒ : ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä¸€è¦§ (2è¡Œã‚«ãƒ¼ãƒ‰å½¢å¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with left_col:
    st.markdown('<div class="section-header">ğŸ† ä¸€è¦§</div>', unsafe_allow_html=True)

    if not ranking_rows:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ•ã‚£ãƒ«ã‚¿ (ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ)
        if total_scores > 0:
            fc1, fc2 = st.columns(2)
            with fc1:
                min_score = st.slider("æœ€ä½ã‚¹ã‚³ã‚¢", 0, 100, 0, 5, key="filter_score")
            with fc2:
                category_filter = st.multiselect("åŒºåˆ†", ["æ³¨ç›®", "è¦ç¢ºèª", "é€šå¸¸"], default=["æ³¨ç›®", "è¦ç¢ºèª"], key="filter_cat")

            # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
            filtered_rows = []
            filtered_codes = []
            for row, code in zip(ranking_rows, ranking_codes):
                if row["score"] != "-" and row["score"] < min_score:
                    continue
                if category_filter and row["category"] not in category_filter:
                    continue
                filtered_rows.append(row)
                filtered_codes.append(code)
        else:
            filtered_rows = ranking_rows
            filtered_codes = ranking_codes

        # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ (å®Ÿéš›ã®é¸æŠç”¨)
        code_label_map = {code: f"{row['code']} {row['name']}" for row, code in zip(filtered_rows, filtered_codes)}
        default_idx = 0
        if st.session_state.selected_code in filtered_codes:
            default_idx = filtered_codes.index(st.session_state.selected_code)

        selected = st.selectbox(
            f"éŠ˜æŸ„é¸æŠ ({len(filtered_rows)}ä»¶)",
            options=filtered_codes,
            index=default_idx,
            format_func=lambda c: code_label_map.get(c, c),
            key="stock_selector",
        )
        st.session_state.selected_code = selected

        # 2è¡Œã‚«ãƒ¼ãƒ‰ã®HTMLè¡¨ç¤º
        cat_colors = {"æ³¨ç›®": "#e74c3c", "è¦ç¢ºèª": "#f39c12", "é€šå¸¸": "#95a5a6", "-": "#bbb"}
        cards_html = '<div style="max-height:580px;overflow-y:auto;border:1px solid #e0e0e0;border-radius:8px;">'
        for row, code in zip(filtered_rows, filtered_codes):
            is_sel = code == selected
            bg = "#e8f0fe" if is_sel else "#fff"
            border_l = "border-left:4px solid #667eea;" if is_sel else "border-left:4px solid transparent;"
            cat_c = cat_colors.get(row["category"], "#95a5a6")
            score_display = f'{row["score"]}' if row["score"] != "-" else "-"
            cards_html += f'''<div style="padding:5px 8px;border-bottom:1px solid #f0f0f0;background:{bg};{border_l}">
  <div style="display:flex;justify-content:space-between;align-items:center;line-height:1.3;">
    <span style="font-size:13px;"><b>{row["code"]}</b> {row["name"][:8]} <span style="color:#999;font-size:11px;">{row["sector"]}</span></span>
    <span style="display:flex;gap:3px;align-items:center;">
      <span style="background:{cat_c};color:white;padding:0 5px;border-radius:6px;font-size:11px;">{row["category"]}{score_display}</span>
      <span style="font-size:11px;">{row["pdf"]}</span>
    </span>
  </div>
  <div style="display:flex;gap:6px;font-size:11px;color:#555;line-height:1.3;">
    <span>å£²<b>{row["yoy_sales"]}</b></span>
    <span>å–¶<b>{row["yoy_op"]}</b></span>
    <span>ç´”<b>{row["yoy_profit"]}</b></span>
    <span>é€²æ—<b>{row["progress"]}%</b></span>
  </div>
</div>'''
        cards_html += '</div>'
        st.markdown(cards_html, unsafe_allow_html=True)

        # é¸æŠä¸­ã®éŠ˜æŸ„ã«å¯¾ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
        if st.session_state.selected_code:
            sel = st.session_state.selected_code
            tdoc = tdnet_map.get(sel, {})

            ac1, ac2, ac3 = st.columns(3)
            with ac1:
                if tdoc.get("document_url"):
                    st.link_button("ğŸ“„ TDnet", tdoc["document_url"], use_container_width=True)
                else:
                    st.button("ğŸ“„ TDnet", disabled=True, use_container_width=True, key="left_tdnet_dis")
            with ac2:
                pp = tdoc.get("pdf_local_path", "")
                if pp and Path(pp).exists():
                    st.download_button("ğŸ“¥ PDF", data=Path(pp).read_bytes(),
                                       file_name=Path(pp).name, mime="application/pdf",
                                       use_container_width=True, key="left_pdf_dl")
                else:
                    st.button("ğŸ“¥ PDF", disabled=True, use_container_width=True, key="left_pdf_dis")
            with ac3:
                if st.button("ğŸ¤– AIåˆ†æ", use_container_width=True, key="left_ai_btn"):
                    with st.spinner(f"{sel} AIåˆ†æä¸­..."):
                        result = run_single_ai_analysis(sel, target_date_str)
                        if result.get("is_error"):
                            st.error(result.get("error", ""))
                        else:
                            st.success("å®Œäº†!")
                    st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å³ã‚«ãƒ©ãƒ : éŠ˜æŸ„è©³ç´°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with right_col:
    st.markdown('<div class="section-header">ğŸ” éŠ˜æŸ„è©³ç´°</div>', unsafe_allow_html=True)

    selected_code = st.session_state.selected_code

    if not selected_code:
        st.info("â† ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„")
    else:
        # éŠ˜æŸ„æƒ…å ±å–å¾—
        session = get_session()
        try:
            stock = session.query(Stock).filter_by(code=selected_code).first()
            stock_name = stock.name if stock else ""
            stock_sector = stock.sector_33_name if stock else ""
            if not stock_name:
                ti = tdnet_map.get(selected_code, {})
                stock_name = ti.get("company_name", "")
        finally:
            session.close()

        st.markdown(f"### {selected_code} {stock_name}")
        if stock_sector:
            st.caption(f"ã‚»ã‚¯ã‚¿ãƒ¼: {stock_sector}")

        # â”€â”€ ã‚¿ãƒ–ã§æ•´ç† â”€â”€
        tab_financial, tab_ai, tab_docs = st.tabs(["ğŸ“ˆ æ¥­ç¸¾", "ğŸ¤– AIåˆ†æ", "ğŸ“„ é–‹ç¤ºè³‡æ–™"])

        # â”€â”€â”€ ã‚¿ãƒ–1: æ¥­ç¸¾ â”€â”€â”€
        with tab_financial:
            session = get_session()
            try:
                all_stmts = (
                    session.query(FinancialStatement).filter_by(code=selected_code)
                    .order_by(FinancialStatement.current_period_end_date.asc()).all()
                )
                session.expunge_all()
            finally:
                session.close()

            if all_stmts:
                # ãƒãƒ£ãƒ¼ãƒˆ
                chart_data = []
                for s in all_stmts:
                    lbl = ""
                    if s.current_fiscal_year_end_date and s.type_of_current_period:
                        lbl = f"{s.current_fiscal_year_end_date.strftime('%Y')} {s.type_of_current_period}"
                    chart_data.append({"æœŸé–“": lbl, "å£²ä¸Šé«˜": s.net_sales, "å–¶æ¥­åˆ©ç›Š": s.operating_profit, "ç´”åˆ©ç›Š": s.profit})

                cdf = pd.DataFrame(chart_data)
                if not cdf.empty and cdf["æœŸé–“"].any():
                    fig = go.Figure()
                    fig.add_trace(go.Bar(x=cdf["æœŸé–“"], y=cdf["å£²ä¸Šé«˜"], name="å£²ä¸Šé«˜", marker_color="#667eea"))
                    fig.add_trace(go.Scatter(x=cdf["æœŸé–“"], y=cdf["å–¶æ¥­åˆ©ç›Š"], name="å–¶æ¥­åˆ©ç›Š",
                                             mode="lines+markers", line=dict(color="#e74c3c", width=3), yaxis="y2"))
                    fig.add_trace(go.Scatter(x=cdf["æœŸé–“"], y=cdf["ç´”åˆ©ç›Š"], name="ç´”åˆ©ç›Š",
                                             mode="lines+markers", line=dict(color="#2ecc71", width=2, dash="dot"), yaxis="y2"))
                    fig.update_layout(
                        height=300, margin=dict(l=10, r=10, t=20, b=10),
                        yaxis=dict(title="å£²ä¸Šé«˜", side="left"),
                        yaxis2=dict(title="åˆ©ç›Š", overlaying="y", side="right"),
                        legend=dict(orientation="h", y=-0.2), hovermode="x unified",
                    )
                    st.plotly_chart(fig, use_container_width=True)

                # YoY/QoQæ¯”è¼ƒ
                fa = FinancialAnalyzer()
                yoy = fa.compare_year_over_year(selected_code)
                qoq = fa.compare_quarter_over_quarter(selected_code)

                comp_col1, comp_col2 = st.columns(2)
                with comp_col1:
                    st.markdown("**å‰å¹´åŒæœŸæ¯” (YoY)**")
                    for label, key in [("å£²ä¸Šé«˜", "yoy_net_sales"), ("å–¶æ¥­åˆ©ç›Š", "yoy_operating_profit"), ("ç´”åˆ©ç›Š", "yoy_profit")]:
                        v = yoy.get(key)
                        st.markdown(f"- {label}: **{v:+.1f}%**" if v is not None else f"- {label}: -")
                with comp_col2:
                    st.markdown("**å‰å››åŠæœŸæ¯” (QoQ)**")
                    for label, key in [("å£²ä¸Šé«˜", "qoq_net_sales"), ("å–¶æ¥­åˆ©ç›Š", "qoq_operating_profit"), ("ç´”åˆ©ç›Š", "qoq_profit")]:
                        v = qoq.get(key)
                        st.markdown(f"- {label}: **{v:+.1f}%**" if v is not None else f"- {label}: -")

                # é€šæœŸäºˆæƒ³é€²æ—
                prog = get_forecast_progress_batch([selected_code], dt).get(selected_code, {})
                if prog and prog.get("standard"):
                    st.markdown("**ğŸ“Š é€šæœŸäºˆæƒ³é€²æ—**")
                    pc1, pc2, pc3 = st.columns(3)
                    for col, label in zip([pc1, pc2, pc3], ["å£²ä¸Š", "å–¶åˆ©", "ç´”åˆ©"]):
                        val = prog.get(label)
                        std = prog["standard"]
                        if val is not None:
                            color = "ğŸŸ¢" if val >= std else ("ğŸŸ¡" if val >= std * 0.8 else "ğŸ”´")
                            col.metric(label, f"{color} {val:.0f}%", delta=f"æ¨™æº–{std}%")
                        else:
                            col.metric(label, "N/A")

                # ã‚·ã‚°ãƒŠãƒ«
                signals = fa.detect_signals(selected_code)
                if signals:
                    st.markdown("**âš¡ æ¤œå‡ºã‚·ã‚°ãƒŠãƒ«**")
                    for sig in signals:
                        st.markdown(f"- {sig}")
            else:
                st.info("æ±ºç®—ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆJ-Quantsæ±ºç®—æƒ…å ±ã‚’åŒæœŸã—ã¦ãã ã•ã„ï¼‰")

        # â”€â”€â”€ ã‚¿ãƒ–2: AIåˆ†æ â”€â”€â”€
        with tab_ai:
            session = get_session()
            try:
                ai_result = (
                    session.query(AIAnalysisResult).filter_by(code=selected_code)
                    .order_by(AIAnalysisResult.analyzed_at.desc()).first()
                )
                if ai_result:
                    session.expunge(ai_result)
            finally:
                session.close()

            if ai_result and ai_result.summary:
                display = parse_ai_display(ai_result)

                if display.get("is_error"):
                    st.warning(f"å‰å›ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼: {display['error'][:100]}")
                    st.info("ä¸Šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰ã€ŒğŸ¤– AIåˆ†æã€ã§å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    sentiment_emoji = {"positive": "ğŸŸ¢ ãƒã‚¸ãƒ†ã‚£ãƒ–", "negative": "ğŸ”´ ãƒã‚¬ãƒ†ã‚£ãƒ–", "neutral": "ğŸŸ¡ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"}
                    st.markdown(f"**ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ:** {sentiment_emoji.get(display['sentiment'], 'â“')}")

                    st.markdown("**ğŸ“ è¦ç´„:**")
                    st.markdown(display["summary"])

                    if display["key_points"]:
                        st.markdown("**ğŸ”‘ æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ:**")
                        for kp in display["key_points"]:
                            st.markdown(f"- {kp}")

                    if display["keywords"]:
                        st.markdown("**ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                        st.markdown(" ".join(
                            f'<span style="background:#667eea;color:white;padding:2px 8px;border-radius:10px;margin:2px;display:inline-block;font-size:12px">{kw}</span>'
                            for kw in display["keywords"]
                        ), unsafe_allow_html=True)

                    if display["signal_words"]:
                        st.markdown("**âš¡ ã‚·ã‚°ãƒŠãƒ«ãƒ¯ãƒ¼ãƒ‰:**")
                        for sw in display["signal_words"]:
                            st.markdown(f"- {sw}")

                    st.caption(f"ãƒ¢ãƒ‡ãƒ«: {ai_result.model_used} | åˆ†æ: {ai_result.analyzed_at}")
            else:
                st.info("AIåˆ†æçµæœãªã—ã€‚å·¦å´ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰ã€ŒğŸ¤– AIåˆ†æã€ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

        # â”€â”€â”€ ã‚¿ãƒ–3: é–‹ç¤ºè³‡æ–™ â”€â”€â”€
        with tab_docs:
            session = get_session()
            try:
                all_docs = (
                    session.query(TDnetDisclosure)
                    .filter(TDnetDisclosure.code == selected_code, TDnetDisclosure.disclosed_date == dt)
                    .all()
                )
                docs_data = [{"title": d.title, "document_url": d.document_url, "pdf_local_path": d.pdf_local_path} for d in all_docs]
            finally:
                session.close()

            if docs_data:
                for di, doc in enumerate(docs_data):
                    st.markdown(f"**{doc['title'] or 'æ›¸é¡'}**")
                    dc1, dc2 = st.columns(2)
                    if doc["document_url"]:
                        dc1.link_button("ğŸ”— TDnetã§é–‹ã", doc["document_url"], use_container_width=True)
                    lp = doc.get("pdf_local_path", "")
                    if lp and Path(lp).exists():
                        dc2.download_button("ğŸ“¥ ä¿å­˜æ¸ˆPDF", data=Path(lp).read_bytes(),
                                            file_name=Path(lp).name, mime="application/pdf",
                                            use_container_width=True, key=f"doc_pdf_{di}")
                    else:
                        dc2.caption("æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                    st.divider()
            else:
                st.info("TDneté–‹ç¤ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ•ãƒƒã‚¿ãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.divider()
st.caption("KessanView â€” ãƒ‡ãƒ¼ã‚¿: J-Quants API / TDnet WEB-API | AI: Google Gemini")
