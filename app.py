"""KessanView - æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ«

ã‚·ãƒ³ã‚°ãƒ«ãƒšãƒ¼ã‚¸æ§‹æˆã®Streamlitã‚¢ãƒ—ãƒªã€‚
ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§å…¨æƒ…å ±ã‚’é–²è¦§å¯èƒ½ã€‚è¨­å®šã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«é…ç½®ã€‚
"""
import json
import logging
import sys
from datetime import date, datetime, timedelta
from pathlib import Path

import pandas as pd
import plotly.graph_objects as go
import streamlit as st

# ãƒ‘ã‚¹è¨­å®š
sys.path.insert(0, str(Path(__file__).resolve().parent))

import config
from db.database import get_session, init_db
from models.schemas import (
    AIAnalysisResult,
    DailyPrice,
    EarningsScore,
    FinancialStatement,
    Stock,
    TDnetDisclosure,
)
from services.financial_analysis import FinancialAnalyzer
from services.scoring import ScoringService

# â”€â”€ ãƒ­ã‚°è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# â”€â”€ ãƒšãƒ¼ã‚¸è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="KessanView - æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# â”€â”€ ã‚«ã‚¹ã‚¿ãƒ CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
    .main .block-container {
        padding-top: 1rem;
        max-width: 1400px;
    }
    div[data-testid="stMetric"] {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-radius: 12px;
        padding: 16px;
        border-left: 4px solid #667eea;
    }
    .section-header {
        background: linear-gradient(90deg, #667eea, #764ba2);
        color: white;
        padding: 8px 16px;
        border-radius: 8px;
        margin: 16px 0 8px 0;
        font-size: 18px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ DBåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
init_db()

# â”€â”€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "selected_code" not in st.session_state:
    st.session_state.selected_code = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def get_forecast_progress_batch(codes: list, dt) -> dict:
    """è¤‡æ•°éŠ˜æŸ„ã®é€šæœŸäºˆæƒ³é€²æ—ç‡ã‚’ä¸€æ‹¬å–å¾—"""
    session = get_session()
    try:
        stmts = (
            session.query(FinancialStatement)
            .filter(
                FinancialStatement.code.in_(codes),
                FinancialStatement.disclosed_date == dt,
            )
            .all()
        )
        results = {}
        for stmt in stmts:
            period = stmt.type_of_current_period or ""
            standard = {"1Q": 25, "2Q": 50, "3Q": 75, "FY": 100}.get(period, 0)
            prog = {}
            for label, af, ff in [
                ("å£²ä¸Š", "net_sales", "forecast_net_sales"),
                ("å–¶åˆ©", "operating_profit", "forecast_operating_profit"),
                ("ç´”åˆ©", "profit", "forecast_profit"),
            ]:
                actual = getattr(stmt, af, None)
                forecast = getattr(stmt, ff, None)
                if actual is not None and forecast and forecast != 0:
                    prog[label] = round(actual / forecast * 100, 1)
            results[stmt.code] = {"period": period, "standard": standard, **prog}
        return results
    finally:
        session.close()


def get_tdnet_map(dt) -> dict:
    """å¯¾è±¡æ—¥ã®TDneté–‹ç¤ºæƒ…å ±ã‚’codeâ†’docè¾æ›¸ã§ä¸€æ‹¬å–å¾—"""
    session = get_session()
    try:
        docs = (
            session.query(TDnetDisclosure)
            .filter(
                TDnetDisclosure.disclosed_date == dt,
                TDnetDisclosure.is_earnings_report == 1,
            )
            .all()
        )
        result = {}
        for d in docs:
            if d.code:
                result[d.code] = {
                    "document_url": d.document_url or "",
                    "pdf_local_path": d.pdf_local_path or "",
                    "company_name": d.company_name or "",
                    "title": d.title or "",
                }
        return result
    finally:
        session.close()


def run_single_ai_analysis(code: str, dt_str: str):
    """å˜ä¸€éŠ˜æŸ„ã®AIåˆ†æã‚’å®Ÿè¡Œ"""
    from services.ai_analyzer import AIAnalyzer

    session = get_session()
    try:
        disclosure = (
            session.query(TDnetDisclosure)
            .filter(
                TDnetDisclosure.code == code,
                TDnetDisclosure.disclosed_date == datetime.strptime(dt_str, "%Y-%m-%d").date(),
                TDnetDisclosure.is_earnings_report == 1,
            )
            .first()
        )
        if not disclosure or not disclosure.pdf_local_path:
            return {"is_error": True, "error": "PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        pdf_path = disclosure.pdf_local_path
        company_name = disclosure.company_name or ""
    finally:
        session.close()

    analyzer = AIAnalyzer()
    return analyzer.analyze_and_save(
        pdf_path=pdf_path,
        code=code,
        disclosed_date=dt_str,
        disclosure_number="",
        company_name=company_name,
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    st.subheader("ğŸ“… å¯¾è±¡æ—¥ä»˜")
    try:
        default_date = datetime.strptime(config.DEV_TEST_DATE, "%Y-%m-%d").date()
    except:
        default_date = date.today()

    target_date = st.date_input("åˆ†æå¯¾è±¡æ—¥", value=default_date, help="æ±ºç®—ç™ºè¡¨æ—¥ã‚’æŒ‡å®š")
    target_date_str = target_date.strftime("%Y-%m-%d")

    st.divider()

    st.subheader("ğŸ”‘ APIè¨­å®š")
    st.caption(f"J-Quants ãƒ—ãƒ©ãƒ³: **{config.JQUANTS_PLAN.upper()}**")
    st.caption(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {config.JQUANTS_RATE_LIMITS.get(config.JQUANTS_PLAN, '?')} req/min")
    st.caption(f"J-Quants: {'âœ…' if config.JQUANTS_API_KEY else 'âŒ'} | Gemini: {'âœ…' if config.GEMINI_API_KEY else 'âŒ'}")

    st.divider()

    st.subheader("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é‡ã¿")
    w = dict(config.DEFAULT_SCORING_WEIGHTS)
    w["yoy_sales"] = st.slider("å£²ä¸Šé«˜YoY", 0.0, 1.0, w["yoy_sales"], 0.05)
    w["yoy_operating_income"] = st.slider("å–¶æ¥­åˆ©ç›ŠYoY", 0.0, 1.0, w["yoy_operating_income"], 0.05)
    w["yoy_profit"] = st.slider("ç´”åˆ©ç›ŠYoY", 0.0, 1.0, w["yoy_profit"], 0.05)
    w["qoq_acceleration"] = st.slider("QoQåŠ é€Ÿåº¦", 0.0, 1.0, w["qoq_acceleration"], 0.05)
    w["revision_flag"] = st.slider("æ¥­ç¸¾ä¿®æ­£", 0.0, 1.0, w["revision_flag"], 0.05)
    w["turnaround_flag"] = st.slider("èµ¤é»’è»¢æ›", 0.0, 1.0, w["turnaround_flag"], 0.05)
    total_w = sum(w.values())
    if total_w > 0:
        w = {k: v / total_w for k, v in w.items()}

    st.divider()
    st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿åŒæœŸ")

    sync_type = st.selectbox(
        "åŒæœŸã‚¿ã‚¤ãƒ—",
        ["éŠ˜æŸ„ãƒã‚¹ã‚¿", "æ±ºç®—æƒ…å ± (æ—¥ä»˜æŒ‡å®š)", "æ ªä¾¡ (æ—¥ä»˜æŒ‡å®š)", "TDneté–‹ç¤ºæƒ…å ±", "å…¨ã¦"],
    )

    if st.button("â–¶ï¸ åŒæœŸå®Ÿè¡Œ", type="primary", use_container_width=True):
        try:
            if sync_type in ["éŠ˜æŸ„ãƒã‚¹ã‚¿", "å…¨ã¦"]:
                from services.sync import SyncService
                with st.spinner("éŠ˜æŸ„ãƒã‚¹ã‚¿åŒæœŸä¸­..."):
                    st.success(f"éŠ˜æŸ„ãƒã‚¹ã‚¿: {SyncService().sync_listed_info()}ä»¶åŒæœŸå®Œäº†")
            if sync_type in ["æ±ºç®—æƒ…å ± (æ—¥ä»˜æŒ‡å®š)", "å…¨ã¦"]:
                from services.sync import SyncService
                with st.spinner(f"æ±ºç®—æƒ…å ±åŒæœŸä¸­... ({target_date_str})"):
                    st.success(f"æ±ºç®—æƒ…å ±: {SyncService().sync_statements_by_date(target_date_str)}ä»¶åŒæœŸå®Œäº†")
            if sync_type in ["æ ªä¾¡ (æ—¥ä»˜æŒ‡å®š)", "å…¨ã¦"]:
                from services.sync import SyncService
                with st.spinner(f"æ ªä¾¡åŒæœŸä¸­... ({target_date_str})"):
                    st.success(f"æ ªä¾¡: {SyncService().sync_daily_prices_by_date(target_date_str)}ä»¶åŒæœŸå®Œäº†")
            if sync_type in ["TDneté–‹ç¤ºæƒ…å ±", "å…¨ã¦"]:
                from services.tdnet import TDnetClient
                tdnet = TDnetClient()
                with st.spinner(f"TDnetåŒæœŸä¸­... ({target_date_str})"):
                    disclosures = tdnet.get_disclosures_by_date(target_date_str)
                    st.success(f"TDnet: {tdnet.save_disclosures_to_db(disclosures, target_date_str)}ä»¶åŒæœŸå®Œäº†")
        except Exception as e:
            st.error(f"åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ“¥ æ±ºç®—çŸ­ä¿¡PDFä¸€æ‹¬DL", use_container_width=True):
        try:
            from services.tdnet import TDnetClient
            with st.spinner(f"PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... ({target_date_str})"):
                results = TDnetClient().download_all_earnings_pdfs(target_date_str)
                st.success(f"PDF: {sum(1 for r in results if r['success'])}/{len(results)}ä»¶DLå®Œäº†")
        except Exception as e:
            st.error(f"PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ¤– AIåˆ†æä¸€æ‹¬å®Ÿè¡Œ", use_container_width=True):
        try:
            from services.ai_analyzer import AIAnalyzer
            analyzer = AIAnalyzer()
            session = get_session()
            try:
                dt_tmp = datetime.strptime(target_date_str, "%Y-%m-%d").date()
                items = [
                    {"pdf_path": d.pdf_local_path, "code": d.code,
                     "disclosed_date": target_date_str, "company_name": d.company_name}
                    for d in session.query(TDnetDisclosure).filter(
                        TDnetDisclosure.disclosed_date == dt_tmp,
                        TDnetDisclosure.is_earnings_report == 1,
                        TDnetDisclosure.pdf_local_path != "",
                    ).all()
                ]
            finally:
                session.close()
            if items:
                pb = st.progress(0, text="AIåˆ†æä¸­...")
                results = analyzer.batch_analyze(items, progress_callback=lambda c, t: pb.progress(c / t, text=f"AIåˆ†æä¸­... {c}/{t}"))
                st.success(f"AIåˆ†æ: {sum(1 for r in results if r.get('success'))}/{len(results)}ä»¶å®Œäº†")
            else:
                st.warning("åˆ†æå¯¾è±¡ã®PDFãŒã‚ã‚Šã¾ã›ã‚“")
        except Exception as e:
            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œ", use_container_width=True):
        try:
            with st.spinner("ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­..."):
                results = ScoringService(weights=w).score_all_for_date(target_date_str)
                st.success(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: {len(results)}ä»¶å®Œäº†")
                st.rerun()
        except Exception as e:
            st.error(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ˜ãƒƒãƒ€ãƒ¼ + ã‚µãƒãƒªãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ“Š KessanView")
st.caption("æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ« â€” æ±ºç®—çŸ­ä¿¡ã®åŠ¹ç‡çš„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")

dt = datetime.strptime(target_date_str, "%Y-%m-%d").date()

session = get_session()
try:
    total_statements = session.query(FinancialStatement).filter(FinancialStatement.disclosed_date == dt).count()
    total_scores = session.query(EarningsScore).filter(EarningsScore.disclosed_date == dt).count()
    attention_count = session.query(EarningsScore).filter(EarningsScore.disclosed_date == dt, EarningsScore.category == "æ³¨ç›®").count()
    check_count = session.query(EarningsScore).filter(EarningsScore.disclosed_date == dt, EarningsScore.category == "è¦ç¢ºèª").count()
    ai_count = session.query(AIAnalysisResult).filter(AIAnalysisResult.disclosed_date == dt).count()
    tdnet_count = session.query(TDnetDisclosure).filter(TDnetDisclosure.disclosed_date == dt, TDnetDisclosure.is_earnings_report == 1).count()
finally:
    session.close()

c1, c2, c3, c4, c5, c6 = st.columns(6)
c1.metric("ğŸ“… å¯¾è±¡æ—¥", target_date_str)
c2.metric("ğŸ“‹ æ±ºç®—ç™ºè¡¨", f"{total_statements}ä»¶")
c3.metric("ğŸ† æ³¨ç›®", f"{attention_count}ä»¶")
c4.metric("ğŸ‘ï¸ è¦ç¢ºèª", f"{check_count}ä»¶")
c5.metric("ğŸ“„ TDnet", f"{tdnet_count}ä»¶")
c6.metric("ğŸ¤– AIåˆ†ææ¸ˆ", f"{ai_count}ä»¶")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TDnetæƒ…å ±ã‚’ä¸€æ‹¬å–å¾— (å…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å…±æœ‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
tdnet_map = get_tdnet_map(dt)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="section-header">ğŸ† é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°</div>', unsafe_allow_html=True)

if total_scores == 0 and tdnet_count > 0:
    # â”€â”€ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æœªå®Ÿæ–½: TDneté–‹ç¤ºä¸€è¦§ã‚’è¡¨ç¤º â”€â”€
    st.info("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚TDneté–‹ç¤ºæƒ…å ±ã‚’ä¸€è¦§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")

    tdnet_rows = []
    for code, info in sorted(tdnet_map.items()):
        tdnet_rows.append({
            "ã‚³ãƒ¼ãƒ‰": code,
            "ä¼æ¥­å": info["company_name"],
            "ã‚¿ã‚¤ãƒˆãƒ«": info["title"][:50],
            "PDF": "âœ…" if info["pdf_local_path"] and Path(info["pdf_local_path"]).exists() else "âŒ",
            "TDnet": "ğŸ”—" if info["document_url"] else "",
        })

    if tdnet_rows:
        tdnet_df = pd.DataFrame(tdnet_rows)
        st.caption(f"ğŸ“„ TDneté–‹ç¤ºæƒ…å ±ï¼ˆæ±ºç®—çŸ­ä¿¡ï¼‰: {len(tdnet_rows)}ä»¶ â€” è¡Œã‚’é¸æŠã—ã¦è©³ç´°è¡¨ç¤º")

        event = st.dataframe(
            tdnet_df,
            width="stretch",
            hide_index=True,
            on_select="rerun",
            selection_mode="single-row",
            height=min(600, 35 * len(tdnet_rows) + 40),
            key="tdnet_ranking",
        )

        # é¸æŠã•ã‚ŒãŸè¡Œã®éŠ˜æŸ„ã‚’å–å¾— + ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³è¡¨ç¤º
        if event and event.selection and event.selection.rows:
            sel_idx = event.selection.rows[0]
            if sel_idx < len(tdnet_rows):
                sel_code = tdnet_rows[sel_idx]["ã‚³ãƒ¼ãƒ‰"]
                st.session_state.selected_code = sel_code
                sel_info = tdnet_map.get(sel_code, {})

                st.markdown(f"**é¸æŠä¸­: {sel_code} {sel_info.get('company_name', '')}**")
                btn_c1, btn_c2, btn_c3 = st.columns(3)
                with btn_c1:
                    if sel_info.get("document_url"):
                        st.link_button("ğŸ“„ TDnetã§é–‹ã", sel_info["document_url"], use_container_width=True)
                    else:
                        st.button("ğŸ“„ TDnetæœªå–å¾—", disabled=True, use_container_width=True)
                with btn_c2:
                    pp = sel_info.get("pdf_local_path", "")
                    if pp and Path(pp).exists():
                        st.download_button("ğŸ“¥ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=Path(pp).read_bytes(),
                                           file_name=Path(pp).name, mime="application/pdf",
                                           use_container_width=True, key="tdnet_sel_dl")
                    else:
                        st.button("ğŸ“¥ PDFæœªDL", disabled=True, use_container_width=True)
                with btn_c3:
                    if st.button("ğŸ¤– AIåˆ†æå®Ÿè¡Œ", use_container_width=True, key="tdnet_sel_ai"):
                        with st.spinner(f"{sel_code} AIåˆ†æä¸­..."):
                            result = run_single_ai_analysis(sel_code, target_date_str)
                            if result.get("is_error"):
                                st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {result.get('error', '')}")
                            else:
                                st.success("AIåˆ†æå®Œäº†!")
                        st.rerun()

elif total_scores == 0:
    st.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ‡ãƒ¼ã‚¿åŒæœŸã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

else:
    # â”€â”€ ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° (st.dataframe) â”€â”€
    # ãƒ•ã‚£ãƒ«ã‚¿
    fc1, fc2, fc3 = st.columns([1, 1, 2])
    with fc1:
        min_score = st.slider("æœ€ä½ã‚¹ã‚³ã‚¢", 0, 100, 0, 5)
    with fc2:
        category_filter = st.multiselect("ã‚«ãƒ†ã‚´ãƒª", ["æ³¨ç›®", "è¦ç¢ºèª", "é€šå¸¸"], default=["æ³¨ç›®", "è¦ç¢ºèª"])
    with fc3:
        session = get_session()
        try:
            sectors = [r[0] for r in session.query(Stock.sector_33_name).distinct().all() if r[0]]
        finally:
            session.close()
        sector_filter = st.multiselect("ã‚»ã‚¯ã‚¿ãƒ¼", sectors)

    # ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—
    session = get_session()
    try:
        query = (
            session.query(EarningsScore, Stock.name, Stock.sector_33_name)
            .outerjoin(Stock, EarningsScore.code == Stock.code)
            .filter(EarningsScore.disclosed_date == dt, EarningsScore.total_score >= min_score)
        )
        if category_filter:
            query = query.filter(EarningsScore.category.in_(category_filter))
        scores_data = query.order_by(EarningsScore.total_score.desc()).all()
    finally:
        session.close()

    # é€²æ—ç‡ã‚’ä¸€æ‹¬å–å¾—
    all_codes = [s.code for s, _, _ in scores_data]
    progress_map = get_forecast_progress_batch(all_codes, dt)

    # DataFrameã‚’æ§‹ç¯‰
    rows = []
    row_codes = []
    for score, name, sector in scores_data:
        if sector_filter and sector not in sector_filter:
            continue
        prog = progress_map.get(score.code, {})
        prog_profit = prog.get("ç´”åˆ©")
        std = prog.get("standard", 0)
        tdoc = tdnet_map.get(score.code, {})

        rows.append({
            "ã‚¹ã‚³ã‚¢": round(score.total_score, 1),
            "åŒºåˆ†": score.category or "é€šå¸¸",
            "ã‚³ãƒ¼ãƒ‰": score.code,
            "éŠ˜æŸ„å": name or "",
            "ã‚»ã‚¯ã‚¿ãƒ¼": (sector or "")[:8],
            "å£²ä¸ŠYoY%": f"{score.yoy_sales_change:+.1f}" if score.yoy_sales_change is not None else "-",
            "å–¶åˆ©YoY%": f"{score.yoy_op_change:+.1f}" if score.yoy_op_change is not None else "-",
            "ç´”åˆ©YoY%": f"{score.yoy_profit_change:+.1f}" if score.yoy_profit_change is not None else "-",
            "ä¿®æ­£": "â†‘" if score.revision_flag == 1 else ("â†“" if score.revision_flag == -1 else "-"),
            "è»¢æ›": "é»’" if score.turnaround_flag == 1 else ("èµ¤" if score.turnaround_flag == -1 else "-"),
            "é€²æ—%": f"{prog_profit:.0f}" if prog_profit is not None else "-",
            "æœŸ": prog.get("period", ""),
            "PDF": "âœ…" if tdoc.get("pdf_local_path") and Path(tdoc["pdf_local_path"]).exists() else ("âŒ" if tdoc else ""),
        })
        row_codes.append(score.code)

    if rows:
        df = pd.DataFrame(rows)
        st.caption(f"è¡¨ç¤º: {len(rows)}ä»¶ / å…¨{total_scores}ä»¶ â€” **è¡Œã‚’é¸æŠã—ã¦è©³ç´°è¡¨ç¤ºãƒ»AIåˆ†æ**")

        event = st.dataframe(
            df,
            width="stretch",
            hide_index=True,
            on_select="rerun",
            selection_mode="single-row",
            height=min(600, 35 * len(rows) + 40),
            column_config={
                "ã‚¹ã‚³ã‚¢": st.column_config.ProgressColumn("ã‚¹ã‚³ã‚¢", min_value=0, max_value=100, format="%.1f"),
            },
            key="score_ranking",
        )

        # é¸æŠã•ã‚ŒãŸè¡Œã®éŠ˜æŸ„ã‚’å–å¾— + ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³è¡¨ç¤º
        if event and event.selection and event.selection.rows:
            sel_idx = event.selection.rows[0]
            if sel_idx < len(row_codes):
                sel_code = row_codes[sel_idx]
                st.session_state.selected_code = sel_code
                sel_tdoc = tdnet_map.get(sel_code, {})
                sel_name = rows[sel_idx].get("éŠ˜æŸ„å", "")

                st.markdown(f"**é¸æŠä¸­: {sel_code} {sel_name}**")
                btn_c1, btn_c2, btn_c3 = st.columns(3)
                with btn_c1:
                    if sel_tdoc.get("document_url"):
                        st.link_button("ğŸ“„ TDnetã§é–‹ã", sel_tdoc["document_url"], use_container_width=True)
                    else:
                        st.button("ğŸ“„ TDnetæœªå–å¾—", disabled=True, use_container_width=True)
                with btn_c2:
                    pp = sel_tdoc.get("pdf_local_path", "")
                    if pp and Path(pp).exists():
                        st.download_button("ğŸ“¥ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=Path(pp).read_bytes(),
                                           file_name=Path(pp).name, mime="application/pdf",
                                           use_container_width=True, key="score_sel_dl")
                    else:
                        st.button("ğŸ“¥ PDFæœªDL", disabled=True, use_container_width=True)
                with btn_c3:
                    if st.button("ğŸ¤– AIåˆ†æå®Ÿè¡Œ", use_container_width=True, key="score_sel_ai"):
                        with st.spinner(f"{sel_code} AIåˆ†æä¸­..."):
                            result = run_single_ai_analysis(sel_code, target_date_str)
                            if result.get("is_error"):
                                st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {result.get('error', '')}")
                            else:
                                st.success("AIåˆ†æå®Œäº†!")
                        st.rerun()
    else:
        st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: éŠ˜æŸ„è©³ç´° (é¸æŠã•ã‚ŒãŸéŠ˜æŸ„)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="section-header">ğŸ” éŠ˜æŸ„è©³ç´°</div>', unsafe_allow_html=True)

# éŠ˜æŸ„é¸æŠç”¨ã®ã‚³ãƒ¼ãƒ‰ä¸€è¦§ã‚’æ§‹ç¯‰ (FinancialStatement + TDnet)
session = get_session()
try:
    codes_from_fs = set(
        r[0] for r in session.query(FinancialStatement.code)
        .filter(FinancialStatement.disclosed_date == dt).distinct().all()
    )
    codes_from_tdnet = set(
        r[0] for r in session.query(TDnetDisclosure.code)
        .filter(TDnetDisclosure.disclosed_date == dt, TDnetDisclosure.is_earnings_report == 1,
                TDnetDisclosure.code != None, TDnetDisclosure.code != "")
        .distinct().all()
    )
    codes_for_date = sorted(codes_from_fs | codes_from_tdnet)
finally:
    session.close()

if codes_for_date:
    # ã‚³ãƒ¼ãƒ‰ â†’ åå‰ãƒãƒƒãƒ”ãƒ³ã‚°
    session = get_session()
    try:
        stock_options = {}
        for code in codes_for_date:
            stock = session.query(Stock).filter_by(code=code).first()
            if stock:
                stock_options[f"{code} {stock.name}"] = code
            else:
                tdnet_info = tdnet_map.get(code, {})
                stock_options[f"{code} {tdnet_info.get('company_name', '')}"] = code
    finally:
        session.close()

    options_list = list(stock_options.keys())
    codes_list = list(stock_options.values())
    default_idx = 0
    if st.session_state.selected_code and st.session_state.selected_code in codes_list:
        default_idx = codes_list.index(st.session_state.selected_code)

    selected_label = st.selectbox(
        "éŠ˜æŸ„ã‚’é¸æŠï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡Œã‚¯ãƒªãƒƒã‚¯ã§ã‚‚é¸æŠå¯èƒ½ï¼‰",
        options=options_list,
        index=default_idx,
    )
    selected_code = stock_options.get(selected_label, "")
    if selected_code != st.session_state.selected_code:
        st.session_state.selected_code = selected_code

    if selected_code:
        # â”€â”€ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¼ â”€â”€
        acol1, acol2, acol3, acol4 = st.columns(4)

        with acol1:
            if st.button("ğŸ¤– ã“ã®éŠ˜æŸ„ã‚’AIåˆ†æ", type="primary", use_container_width=True):
                with st.spinner(f"{selected_code} AIåˆ†æä¸­..."):
                    result = run_single_ai_analysis(selected_code, target_date_str)
                    if result.get("is_error"):
                        st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜')}")
                    else:
                        st.success("AIåˆ†æå®Œäº†ï¼")
                st.rerun()

        tdoc = tdnet_map.get(selected_code, {})
        with acol2:
            if tdoc.get("document_url"):
                st.link_button("ğŸ“„ TDnetã§é–‹ã", tdoc["document_url"], use_container_width=True)
            else:
                st.button("ğŸ“„ TDnetæœªå–å¾—", disabled=True, use_container_width=True, key="detail_tdnet_disabled")

        with acol3:
            pdf_path = tdoc.get("pdf_local_path", "")
            if pdf_path and Path(pdf_path).exists():
                st.download_button(
                    "ğŸ“¥ PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=Path(pdf_path).read_bytes(),
                    file_name=Path(pdf_path).name,
                    mime="application/pdf",
                    use_container_width=True,
                )
            else:
                st.button("ğŸ“¥ PDFæœªDL", disabled=True, use_container_width=True, key="detail_pdf_disabled")

        with acol4:
            prog = get_forecast_progress_batch([selected_code], dt).get(selected_code, {})
            if prog:
                pp = prog.get("ç´”åˆ©")
                std = prog.get("standard", 0)
                period = prog.get("period", "")
                if pp is not None:
                    color = "ğŸŸ¢" if pp >= std else ("ğŸŸ¡" if pp >= std * 0.8 else "ğŸ”´")
                    st.metric(f"é€šæœŸé€²æ— ({period})", f"{color} {pp:.0f}%", delta=f"æ¨™æº–{std}%")
                else:
                    st.metric(f"é€šæœŸé€²æ— ({period})", "N/A")

        # â”€â”€ 2ã‚«ãƒ©ãƒ  â”€â”€
        detail_col1, detail_col2 = st.columns([1, 1])

        # â”€â”€ å·¦: æ¥­ç¸¾æ¨ç§» â”€â”€
        with detail_col1:
            st.subheader("ğŸ“ˆ å››åŠæœŸæ¥­ç¸¾æ¨ç§»")
            session = get_session()
            try:
                all_stmts = (
                    session.query(FinancialStatement).filter_by(code=selected_code)
                    .order_by(FinancialStatement.current_period_end_date.asc()).all()
                )
                session.expunge_all()
            finally:
                session.close()

            if all_stmts:
                chart_data = []
                for s in all_stmts:
                    lbl = ""
                    if s.current_fiscal_year_end_date and s.type_of_current_period:
                        lbl = f"{s.current_fiscal_year_end_date.strftime('%Y')} {s.type_of_current_period}"
                    chart_data.append({"æœŸé–“": lbl, "å£²ä¸Šé«˜": s.net_sales, "å–¶æ¥­åˆ©ç›Š": s.operating_profit, "ç´”åˆ©ç›Š": s.profit})

                cdf = pd.DataFrame(chart_data)
                if not cdf.empty and cdf["æœŸé–“"].any():
                    fig = go.Figure()
                    fig.add_trace(go.Bar(x=cdf["æœŸé–“"], y=cdf["å£²ä¸Šé«˜"], name="å£²ä¸Šé«˜", marker_color="#667eea"))
                    fig.add_trace(go.Scatter(x=cdf["æœŸé–“"], y=cdf["å–¶æ¥­åˆ©ç›Š"], name="å–¶æ¥­åˆ©ç›Š", mode="lines+markers", line=dict(color="#e74c3c", width=3), yaxis="y2"))
                    fig.add_trace(go.Scatter(x=cdf["æœŸé–“"], y=cdf["ç´”åˆ©ç›Š"], name="ç´”åˆ©ç›Š", mode="lines+markers", line=dict(color="#2ecc71", width=2, dash="dot"), yaxis="y2"))
                    fig.update_layout(
                        height=350, margin=dict(l=20, r=20, t=30, b=20),
                        yaxis=dict(title="å£²ä¸Šé«˜", side="left"),
                        yaxis2=dict(title="åˆ©ç›Š", overlaying="y", side="right"),
                        legend=dict(orientation="h", y=-0.15), hovermode="x unified",
                    )
                    st.plotly_chart(fig, use_container_width=True)

                # YoY/QoQæ¯”è¼ƒ
                fa = FinancialAnalyzer()
                yoy = fa.compare_year_over_year(selected_code)
                qoq = fa.compare_quarter_over_quarter(selected_code)

                comp = {
                    "æŒ‡æ¨™": ["å£²ä¸Šé«˜", "å–¶æ¥­åˆ©ç›Š", "çµŒå¸¸åˆ©ç›Š", "ç´”åˆ©ç›Š"],
                    "YoY": [
                        f"{yoy.get('yoy_net_sales'):+.1f}%" if yoy.get("yoy_net_sales") is not None else "-",
                        f"{yoy.get('yoy_operating_profit'):+.1f}%" if yoy.get("yoy_operating_profit") is not None else "-",
                        f"{yoy.get('yoy_ordinary_profit'):+.1f}%" if yoy.get("yoy_ordinary_profit") is not None else "-",
                        f"{yoy.get('yoy_profit'):+.1f}%" if yoy.get("yoy_profit") is not None else "-",
                    ],
                    "QoQ": [
                        f"{qoq.get('qoq_net_sales'):+.1f}%" if qoq.get("qoq_net_sales") is not None else "-",
                        f"{qoq.get('qoq_operating_profit'):+.1f}%" if qoq.get("qoq_operating_profit") is not None else "-",
                        f"{qoq.get('qoq_ordinary_profit'):+.1f}%" if qoq.get("qoq_ordinary_profit") is not None else "-",
                        f"{qoq.get('qoq_profit'):+.1f}%" if qoq.get("qoq_profit") is not None else "-",
                    ],
                }
                st.dataframe(pd.DataFrame(comp), width="stretch", hide_index=True)

                # é€²æ—ãƒ†ãƒ¼ãƒ–ãƒ«
                if prog and prog.get("standard"):
                    st.markdown("**ğŸ“Š é€šæœŸäºˆæƒ³é€²æ—**")
                    pdata = {
                        "æŒ‡æ¨™": ["å£²ä¸Šé«˜", "å–¶æ¥­åˆ©ç›Š", "ç´”åˆ©ç›Š"],
                        "é€²æ—ç‡": [
                            f"{prog.get('å£²ä¸Š', 0):.1f}%" if prog.get("å£²ä¸Š") is not None else "-",
                            f"{prog.get('å–¶åˆ©', 0):.1f}%" if prog.get("å–¶åˆ©") is not None else "-",
                            f"{prog.get('ç´”åˆ©', 0):.1f}%" if prog.get("ç´”åˆ©") is not None else "-",
                        ],
                        "æ¨™æº–": [f"{prog['standard']}%"] * 3,
                    }
                    st.dataframe(pd.DataFrame(pdata), width="stretch", hide_index=True)

                # ã‚·ã‚°ãƒŠãƒ«
                signals = fa.detect_signals(selected_code)
                if signals:
                    st.subheader("âš¡ æ¤œå‡ºã‚·ã‚°ãƒŠãƒ«")
                    for sig in signals:
                        st.markdown(f"- {sig}")
            else:
                st.info("æ±ºç®—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆJ-Quantsæ±ºç®—æƒ…å ±ã‚’åŒæœŸã—ã¦ãã ã•ã„ï¼‰")

        # â”€â”€ å³: AIåˆ†æ + é–‹ç¤ºè³‡æ–™ â”€â”€
        with detail_col2:
            st.subheader("ğŸ¤– AIåˆ†æçµæœ")
            session = get_session()
            try:
                ai_result = (
                    session.query(AIAnalysisResult).filter_by(code=selected_code)
                    .order_by(AIAnalysisResult.analyzed_at.desc()).first()
                )
                if ai_result:
                    session.expunge(ai_result)
            finally:
                session.close()

            if ai_result and ai_result.summary:
                summary_text = ai_result.summary
                # ã‚¨ãƒ©ãƒ¼çµæœã¯å†åˆ†æã‚’ä¿ƒã™
                if summary_text.startswith("åˆ†æã‚¨ãƒ©ãƒ¼:"):
                    st.warning(f"å‰å›ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™: {summary_text[:100]}")
                    st.info("ã€ŒğŸ¤– ã“ã®éŠ˜æŸ„ã‚’AIåˆ†æã€ãƒœã‚¿ãƒ³ã§å†åˆ†æã—ã¦ãã ã•ã„ã€‚")
                else:
                    # summaryã«JSONæ–‡å­—åˆ—ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ãƒªã‚«ãƒãƒª
                    display_summary = summary_text
                    display_kps = []
                    display_kws = []
                    display_sws = []
                    display_sentiment = ai_result.sentiment or "neutral"

                    if summary_text.lstrip().startswith(("{", "```")):
                        import re
                        # JSONã‚’æŠ½å‡ºã—ã¦æ­£ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å–å¾—
                        fence_m = re.search(r'```(?:json)?\s*\n?(\{.*)', summary_text, re.DOTALL)
                        json_candidate = fence_m.group(1).rstrip('`').strip() if fence_m else summary_text.strip().lstrip('`').strip()
                        if json_candidate.count("{") > json_candidate.count("}"):
                            json_candidate += "}" * (json_candidate.count("{") - json_candidate.count("}"))
                        try:
                            parsed = json.loads(json_candidate)
                            display_summary = parsed.get("summary", summary_text[:300])
                            display_kps = parsed.get("key_points", [])
                            display_kws = parsed.get("keywords", [])
                            display_sws = parsed.get("signal_words", [])
                            display_sentiment = parsed.get("sentiment", display_sentiment)
                        except (json.JSONDecodeError, AttributeError):
                            # regexæŠ½å‡ºã«ã‚‚å¤±æ•— â€” summaryã‚­ãƒ¼ã ã‘å–å¾—
                            sum_m = re.search(r'"summary"\s*:\s*"([^"]*)"', summary_text)
                            if sum_m:
                                display_summary = sum_m.group(1)
                    else:
                        # æ­£å¸¸ãªä¿å­˜ãƒ‡ãƒ¼ã‚¿
                        try:
                            display_kps = json.loads(ai_result.key_points) if ai_result.key_points else []
                        except json.JSONDecodeError:
                            display_kps = []
                        try:
                            display_kws = json.loads(ai_result.keywords) if ai_result.keywords else []
                        except json.JSONDecodeError:
                            display_kws = []
                        try:
                            display_sws = json.loads(ai_result.signal_words) if ai_result.signal_words else []
                        except json.JSONDecodeError:
                            display_sws = []

                    sentiment_emoji = {"positive": "ğŸŸ¢ ãƒã‚¸ãƒ†ã‚£ãƒ–", "negative": "ğŸ”´ ãƒã‚¬ãƒ†ã‚£ãƒ–", "neutral": "ğŸŸ¡ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"}
                    st.markdown(f"**ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ:** {sentiment_emoji.get(display_sentiment, 'â“')}")
                    st.markdown("**ğŸ“ è¦ç´„:**")
                    st.markdown(display_summary)

                    if display_kps:
                        st.markdown("**ğŸ”‘ æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ:**")
                        for kp in display_kps:
                            st.markdown(f"- {kp}")

                    if display_kws:
                        st.markdown("**ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                        st.markdown(" ".join(
                            f'<span style="background:#667eea;color:white;padding:2px 8px;border-radius:10px;margin:2px;display:inline-block;font-size:12px">{kw}</span>'
                            for kw in display_kws
                        ), unsafe_allow_html=True)

                    if display_sws:
                        st.markdown("**âš¡ ã‚·ã‚°ãƒŠãƒ«ãƒ¯ãƒ¼ãƒ‰:**")
                        for sw in display_sws:
                            st.markdown(f"- {sw}")

                    st.caption(f"ãƒ¢ãƒ‡ãƒ«: {ai_result.model_used} | åˆ†æ: {ai_result.analyzed_at}")
            else:
                st.info("AIåˆ†æçµæœãªã—ã€‚ã€ŒğŸ¤– ã“ã®éŠ˜æŸ„ã‚’AIåˆ†æã€ãƒœã‚¿ãƒ³ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

            # é–‹ç¤ºè³‡æ–™ä¸€è¦§
            st.subheader("ğŸ“„ é–‹ç¤ºè³‡æ–™")
            session = get_session()
            try:
                all_docs = (
                    session.query(TDnetDisclosure)
                    .filter(TDnetDisclosure.code == selected_code, TDnetDisclosure.disclosed_date == dt)
                    .all()
                )
                docs_data = [{"title": d.title, "document_url": d.document_url, "pdf_local_path": d.pdf_local_path} for d in all_docs]
            finally:
                session.close()

            if docs_data:
                for di, doc in enumerate(docs_data):
                    with st.expander(doc["title"] or "æ›¸é¡"):
                        bc1, bc2 = st.columns(2)
                        if doc["document_url"]:
                            bc1.link_button("ğŸ”— TDnetã§é–‹ã", doc["document_url"], use_container_width=True)
                        lp = doc.get("pdf_local_path", "")
                        if lp and Path(lp).exists():
                            bc2.download_button(
                                "ğŸ“¥ ä¿å­˜æ¸ˆPDFã‚’å–å¾—", data=Path(lp).read_bytes(),
                                file_name=Path(lp).name, mime="application/pdf",
                                use_container_width=True, key=f"dl_{selected_code}_{di}",
                            )
                        else:
                            bc2.caption("æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            else:
                st.info("TDneté–‹ç¤ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
else:
    st.info("å¯¾è±¡æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã—ã¦ãã ã•ã„ã€‚")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: AIåˆ†æã‚µãƒãƒªãƒ¼ä¸€è¦§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="section-header">ğŸ¤– AIåˆ†æã‚µãƒãƒªãƒ¼ä¸€è¦§</div>', unsafe_allow_html=True)

session = get_session()
try:
    ai_all = (
        session.query(AIAnalysisResult, Stock.name)
        .outerjoin(Stock, AIAnalysisResult.code == Stock.code)
        .filter(AIAnalysisResult.disclosed_date == dt).all()
    )
finally:
    session.close()

if ai_all:
    ai_rows = []
    error_count = 0
    for ai, name in ai_all:
        summary = ai.summary or ""
        # ã‚¨ãƒ©ãƒ¼çµæœã¯ã‚¹ã‚­ãƒƒãƒ—
        if summary.startswith("åˆ†æã‚¨ãƒ©ãƒ¼:"):
            error_count += 1
            continue
        try:
            kws = json.loads(ai.keywords) if ai.keywords else []
        except json.JSONDecodeError:
            kws = []
        sentiment_map = {"positive": "ğŸŸ¢ ãƒã‚¸ãƒ†ã‚£ãƒ–", "negative": "ğŸ”´ ãƒã‚¬ãƒ†ã‚£ãƒ–", "neutral": "ğŸŸ¡ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"}
        ai_rows.append({
            "ã‚³ãƒ¼ãƒ‰": ai.code,
            "éŠ˜æŸ„å": name or "",
            "ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ": sentiment_map.get(ai.sentiment, ai.sentiment or ""),
            "è¦ç´„": summary[:120] + ("..." if len(summary) > 120 else ""),
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ", ".join(kws[:5]) if kws else "",
        })
    if ai_rows:
        st.dataframe(pd.DataFrame(ai_rows), width="stretch", hide_index=True)
    if error_count > 0:
        st.caption(f"âš ï¸ {error_count}ä»¶ã®ã‚¨ãƒ©ãƒ¼çµæœã¯éè¡¨ç¤ºï¼ˆAPIåˆ¶é™ç­‰ï¼‰")
    if not ai_rows and error_count == 0:
        st.info("AIåˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“")
else:
    st.info("AIåˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ•ãƒƒã‚¿ãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.divider()
st.caption("KessanView â€” ãƒ‡ãƒ¼ã‚¿: J-Quants API / TDnet WEB-API | AI: Google Gemini")
