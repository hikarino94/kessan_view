"""KessanView - æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ«

ã‚·ãƒ³ã‚°ãƒ«ãƒšãƒ¼ã‚¸æ§‹æˆã®Streamlitã‚¢ãƒ—ãƒªã€‚
ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§å…¨æƒ…å ±ã‚’é–²è¦§å¯èƒ½ã€‚è¨­å®šã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«é…ç½®ã€‚
"""
import json
import logging
import sys
from datetime import date, datetime, timedelta
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# ãƒ‘ã‚¹è¨­å®š
sys.path.insert(0, str(Path(__file__).resolve().parent))

import config
from db.database import get_session, init_db
from models.schemas import (
    AIAnalysisResult,
    DailyPrice,
    EarningsScore,
    FinancialStatement,
    Stock,
    TDnetDisclosure,
)
from services.financial_analysis import FinancialAnalyzer
from services.scoring import ScoringService

# â”€â”€ ãƒ­ã‚°è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# â”€â”€ ãƒšãƒ¼ã‚¸è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="KessanView - æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# â”€â”€ ã‚«ã‚¹ã‚¿ãƒ CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
    /* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ */
    .main .block-container {
        padding-top: 1rem;
        max-width: 1400px;
    }

    /* ã‚¹ã‚³ã‚¢ãƒãƒƒã‚¸ */
    .score-badge-attention {
        background: linear-gradient(135deg, #ff6b6b, #ee5a24);
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 14px;
    }
    .score-badge-check {
        background: linear-gradient(135deg, #feca57, #ff9f43);
        color: #333;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 14px;
    }
    .score-badge-normal {
        background: linear-gradient(135deg, #dfe6e9, #b2bec3);
        color: #333;
        padding: 4px 12px;
        border-radius: 12px;
        font-size: 14px;
    }

    /* ã‚·ã‚°ãƒŠãƒ« */
    .signal-positive { color: #e74c3c; font-weight: bold; }
    .signal-negative { color: #3498db; font-weight: bold; }

    /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ */
    div[data-testid="stMetric"] {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-radius: 12px;
        padding: 16px;
        border-left: 4px solid #667eea;
    }

    /* ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚¿ã‚¤ãƒ« */
    .dataframe { font-size: 13px !important; }

    /* ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ */
    .section-header {
        background: linear-gradient(90deg, #667eea, #764ba2);
        color: white;
        padding: 8px 16px;
        border-radius: 8px;
        margin: 16px 0 8px 0;
        font-size: 18px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ DBåˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
init_db()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    st.subheader("ğŸ“… å¯¾è±¡æ—¥ä»˜")
    try:
        default_date = datetime.strptime(config.DEV_TEST_DATE, "%Y-%m-%d").date()
    except:
        default_date = date.today()

    target_date = st.date_input(
        "åˆ†æå¯¾è±¡æ—¥",
        value=default_date,
        help="æ±ºç®—ç™ºè¡¨æ—¥ã‚’æŒ‡å®šã—ã¦ãã ã•ã„",
    )
    target_date_str = target_date.strftime("%Y-%m-%d")

    st.divider()

    st.subheader("ğŸ”‘ APIè¨­å®š")
    st.caption(f"J-Quants ãƒ—ãƒ©ãƒ³: **{config.JQUANTS_PLAN.upper()}**")
    st.caption(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {config.JQUANTS_RATE_LIMITS.get(config.JQUANTS_PLAN, '?')} req/min")
    jquants_key_set = "âœ… è¨­å®šæ¸ˆã¿" if config.JQUANTS_API_KEY else "âŒ æœªè¨­å®š"
    gemini_key_set = "âœ… è¨­å®šæ¸ˆã¿" if config.GEMINI_API_KEY else "âŒ æœªè¨­å®š"
    st.caption(f"J-Quants API ã‚­ãƒ¼: {jquants_key_set}")
    st.caption(f"Gemini API ã‚­ãƒ¼: {gemini_key_set}")

    st.divider()

    st.subheader("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é‡ã¿")
    w = dict(config.DEFAULT_SCORING_WEIGHTS)
    w["yoy_sales"] = st.slider("å£²ä¸Šé«˜YoY", 0.0, 1.0, w["yoy_sales"], 0.05)
    w["yoy_operating_income"] = st.slider("å–¶æ¥­åˆ©ç›ŠYoY", 0.0, 1.0, w["yoy_operating_income"], 0.05)
    w["yoy_profit"] = st.slider("ç´”åˆ©ç›ŠYoY", 0.0, 1.0, w["yoy_profit"], 0.05)
    w["qoq_acceleration"] = st.slider("QoQåŠ é€Ÿåº¦", 0.0, 1.0, w["qoq_acceleration"], 0.05)
    w["revision_flag"] = st.slider("æ¥­ç¸¾ä¿®æ­£", 0.0, 1.0, w["revision_flag"], 0.05)
    w["turnaround_flag"] = st.slider("èµ¤é»’è»¢æ›", 0.0, 1.0, w["turnaround_flag"], 0.05)

    # åˆè¨ˆã‚’æ­£è¦åŒ–
    total_w = sum(w.values())
    if total_w > 0:
        w = {k: v / total_w for k, v in w.items()}

    st.divider()

    st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿åŒæœŸ")

    sync_type = st.selectbox(
        "åŒæœŸã‚¿ã‚¤ãƒ—",
        ["éŠ˜æŸ„ãƒã‚¹ã‚¿", "æ±ºç®—æƒ…å ± (æ—¥ä»˜æŒ‡å®š)", "æ ªä¾¡ (æ—¥ä»˜æŒ‡å®š)", "TDneté–‹ç¤ºæƒ…å ±", "å…¨ã¦"],
    )

    if st.button("â–¶ï¸ åŒæœŸå®Ÿè¡Œ", type="primary", use_container_width=True):
        try:
            if sync_type == "éŠ˜æŸ„ãƒã‚¹ã‚¿" or sync_type == "å…¨ã¦":
                from services.sync import SyncService
                sync = SyncService()
                with st.spinner("éŠ˜æŸ„ãƒã‚¹ã‚¿åŒæœŸä¸­..."):
                    count = sync.sync_listed_info()
                    st.success(f"éŠ˜æŸ„ãƒã‚¹ã‚¿: {count}ä»¶åŒæœŸå®Œäº†")

            if sync_type in ["æ±ºç®—æƒ…å ± (æ—¥ä»˜æŒ‡å®š)", "å…¨ã¦"]:
                from services.sync import SyncService
                sync = SyncService()
                with st.spinner(f"æ±ºç®—æƒ…å ±åŒæœŸä¸­... ({target_date_str})"):
                    count = sync.sync_statements_by_date(target_date_str)
                    st.success(f"æ±ºç®—æƒ…å ±: {count}ä»¶åŒæœŸå®Œäº†")

            if sync_type in ["æ ªä¾¡ (æ—¥ä»˜æŒ‡å®š)", "å…¨ã¦"]:
                from services.sync import SyncService
                sync = SyncService()
                with st.spinner(f"æ ªä¾¡åŒæœŸä¸­... ({target_date_str})"):
                    count = sync.sync_daily_prices_by_date(target_date_str)
                    st.success(f"æ ªä¾¡: {count}ä»¶åŒæœŸå®Œäº†")

            if sync_type in ["TDneté–‹ç¤ºæƒ…å ±", "å…¨ã¦"]:
                from services.tdnet import TDnetClient
                tdnet = TDnetClient()
                with st.spinner(f"TDnetåŒæœŸä¸­... ({target_date_str})"):
                    disclosures = tdnet.get_disclosures_by_date(target_date_str)
                    count = tdnet.save_disclosures_to_db(disclosures, target_date_str)
                    st.success(f"TDnet: {count}ä»¶åŒæœŸå®Œäº†")

        except Exception as e:
            st.error(f"åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ“¥ æ±ºç®—çŸ­ä¿¡PDFä¸€æ‹¬DL", use_container_width=True):
        try:
            from services.tdnet import TDnetClient
            tdnet = TDnetClient()
            with st.spinner(f"PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... ({target_date_str})"):
                results = tdnet.download_all_earnings_pdfs(target_date_str)
                success = sum(1 for r in results if r["success"])
                st.success(f"PDF: {success}/{len(results)}ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            st.error(f"PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ¤– AIåˆ†æå®Ÿè¡Œ", use_container_width=True):
        try:
            from services.ai_analyzer import AIAnalyzer
            analyzer = AIAnalyzer()
            session = get_session()
            try:
                dt = datetime.strptime(target_date_str, "%Y-%m-%d").date()
                disclosures = (
                    session.query(TDnetDisclosure)
                    .filter(
                        TDnetDisclosure.disclosed_date == dt,
                        TDnetDisclosure.is_earnings_report == 1,
                        TDnetDisclosure.pdf_local_path != "",
                    )
                    .all()
                )
                items = [
                    {
                        "pdf_path": d.pdf_local_path,
                        "code": d.code,
                        "disclosed_date": target_date_str,
                        "company_name": d.company_name,
                    }
                    for d in disclosures
                ]
            finally:
                session.close()

            if items:
                progress_bar = st.progress(0, text="AIåˆ†æä¸­...")
                def update_progress(current, total):
                    progress_bar.progress(current / total, text=f"AIåˆ†æä¸­... {current}/{total}")
                results = analyzer.batch_analyze(items, progress_callback=update_progress)
                success = sum(1 for r in results if r.get("success"))
                st.success(f"AIåˆ†æ: {success}/{len(results)}ä»¶å®Œäº†")
            else:
                st.warning("åˆ†æå¯¾è±¡ã®PDFãŒã‚ã‚Šã¾ã›ã‚“")
        except Exception as e:
            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œ", use_container_width=True):
        try:
            scorer = ScoringService(weights=w)
            with st.spinner("ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¸­..."):
                results = scorer.score_all_for_date(target_date_str)
                st.success(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: {len(results)}ä»¶å®Œäº†")
                st.rerun()
        except Exception as e:
            st.error(f"ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ˜ãƒƒãƒ€ãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ“Š KessanView")
st.caption("æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ« â€” æ±ºç®—çŸ­ä¿¡ã®åŠ¹ç‡çš„ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")

# â”€â”€ ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
session = get_session()
try:
    dt = datetime.strptime(target_date_str, "%Y-%m-%d").date()

    total_statements = session.query(FinancialStatement).filter(
        FinancialStatement.disclosed_date == dt
    ).count()

    total_scores = session.query(EarningsScore).filter(
        EarningsScore.disclosed_date == dt
    ).count()

    attention_count = session.query(EarningsScore).filter(
        EarningsScore.disclosed_date == dt,
        EarningsScore.category == "æ³¨ç›®",
    ).count()

    check_count = session.query(EarningsScore).filter(
        EarningsScore.disclosed_date == dt,
        EarningsScore.category == "è¦ç¢ºèª",
    ).count()

    ai_count = session.query(AIAnalysisResult).filter(
        AIAnalysisResult.disclosed_date == dt,
    ).count()

    tdnet_count = session.query(TDnetDisclosure).filter(
        TDnetDisclosure.disclosed_date == dt,
        TDnetDisclosure.is_earnings_report == 1,
    ).count()
finally:
    session.close()

col1, col2, col3, col4, col5, col6 = st.columns(6)
with col1:
    st.metric("ğŸ“… å¯¾è±¡æ—¥", target_date_str)
with col2:
    st.metric("ğŸ“‹ æ±ºç®—ç™ºè¡¨", f"{total_statements}ä»¶")
with col3:
    st.metric("ğŸ† æ³¨ç›®", f"{attention_count}ä»¶")
with col4:
    st.metric("ğŸ‘ï¸ è¦ç¢ºèª", f"{check_count}ä»¶")
with col5:
    st.metric("ğŸ“„ TDnet", f"{tdnet_count}ä»¶")
with col6:
    st.metric("ğŸ¤– AIåˆ†ææ¸ˆ", f"{ai_count}ä»¶")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="section-header">ğŸ† é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°</div>', unsafe_allow_html=True)

if total_scores == 0:
    st.info("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ‡ãƒ¼ã‚¿åŒæœŸã€â†’ã€Œã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œã€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
else:
    # ãƒ•ã‚£ãƒ«ã‚¿
    filter_col1, filter_col2, filter_col3 = st.columns([1, 1, 2])
    with filter_col1:
        min_score = st.slider("æœ€ä½ã‚¹ã‚³ã‚¢", 0, 100, 0, 5)
    with filter_col2:
        category_filter = st.multiselect(
            "ã‚«ãƒ†ã‚´ãƒª",
            ["æ³¨ç›®", "è¦ç¢ºèª", "é€šå¸¸"],
            default=["æ³¨ç›®", "è¦ç¢ºèª"],
        )
    with filter_col3:
        # ã‚»ã‚¯ã‚¿ãƒ¼ä¸€è¦§ã‚’å–å¾—
        session = get_session()
        try:
            sectors = [r[0] for r in session.query(Stock.sector_33_name).distinct().all() if r[0]]
        finally:
            session.close()
        sector_filter = st.multiselect("ã‚»ã‚¯ã‚¿ãƒ¼", sectors)

    # ã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿å–å¾—
    session = get_session()
    try:
        query = (
            session.query(EarningsScore, Stock.name, Stock.sector_33_name, Stock.market_name)
            .outerjoin(Stock, EarningsScore.code == Stock.code)
            .filter(
                EarningsScore.disclosed_date == dt,
                EarningsScore.total_score >= min_score,
            )
        )
        if category_filter:
            query = query.filter(EarningsScore.category.in_(category_filter))

        scores_with_info = query.order_by(EarningsScore.total_score.desc()).all()
    finally:
        session.close()

    if scores_with_info:
        # DataFrameã«å¤‰æ›
        rows = []
        for score, name, sector, market in scores_with_info:
            if sector_filter and sector not in sector_filter:
                continue
            rows.append({
                "ã‚¹ã‚³ã‚¢": score.total_score,
                "ã‚«ãƒ†ã‚´ãƒª": score.category,
                "ã‚³ãƒ¼ãƒ‰": score.code,
                "éŠ˜æŸ„å": name or "",
                "ã‚»ã‚¯ã‚¿ãƒ¼": sector or "",
                "å¸‚å ´": market or "",
                "å£²ä¸ŠYoY%": f"{score.yoy_sales_change:+.1f}" if score.yoy_sales_change is not None else "-",
                "å–¶åˆ©YoY%": f"{score.yoy_op_change:+.1f}" if score.yoy_op_change is not None else "-",
                "ç´”åˆ©YoY%": f"{score.yoy_profit_change:+.1f}" if score.yoy_profit_change is not None else "-",
                "QoQåŠ é€Ÿ": f"{score.qoq_acceleration:+.1f}" if score.qoq_acceleration is not None else "-",
                "ä¿®æ­£": "â†‘" if score.revision_flag == 1 else ("â†“" if score.revision_flag == -1 else "-"),
                "è»¢æ›": "é»’" if score.turnaround_flag == 1 else ("èµ¤" if score.turnaround_flag == -1 else "-"),
            })

        if rows:
            df = pd.DataFrame(rows)
            st.dataframe(
                df,
                width="stretch",
                height=min(400, 35 * len(rows) + 40),
                column_config={
                    "ã‚¹ã‚³ã‚¢": st.column_config.ProgressColumn(
                        "ã‚¹ã‚³ã‚¢", min_value=0, max_value=100, format="%.1f"
                    ),
                },
            )
            st.caption(f"è¡¨ç¤ºä»¶æ•°: {len(rows)}ä»¶ / å…¨{total_scores}ä»¶")
        else:
            st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: éŠ˜æŸ„è©³ç´°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="section-header">ğŸ” éŠ˜æŸ„è©³ç´°</div>', unsafe_allow_html=True)

# éŠ˜æŸ„é¸æŠ
session = get_session()
try:
    codes_for_date = [
        r[0]
        for r in session.query(FinancialStatement.code)
        .filter(FinancialStatement.disclosed_date == dt)
        .distinct()
        .all()
    ]
finally:
    session.close()

if codes_for_date:
    # ã‚³ãƒ¼ãƒ‰+åå‰ã®ãƒªã‚¹ãƒˆ
    session = get_session()
    try:
        stock_options = {}
        for code in codes_for_date:
            stock = session.query(Stock).filter_by(code=code).first()
            name = stock.name if stock else ""
            stock_options[f"{code} {name}"] = code
    finally:
        session.close()

    selected_label = st.selectbox(
        "éŠ˜æŸ„ã‚’é¸æŠ",
        options=list(stock_options.keys()),
        index=0,
        help="æ±ºç®—ç™ºè¡¨éŠ˜æŸ„ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„",
    )
    selected_code = stock_options.get(selected_label, "")

    if selected_code:
        detail_col1, detail_col2 = st.columns([1, 1])

        # â”€â”€ å·¦ã‚«ãƒ©ãƒ : æ±ºç®—æƒ…å ± â”€â”€â”€â”€â”€â”€
        with detail_col1:
            st.subheader("ğŸ“ˆ å››åŠæœŸæ¥­ç¸¾æ¨ç§»")
            session = get_session()
            try:
                all_statements = (
                    session.query(FinancialStatement)
                    .filter_by(code=selected_code)
                    .order_by(FinancialStatement.current_period_end_date.asc())
                    .all()
                )
                session.expunge_all()
            finally:
                session.close()

            if all_statements:
                chart_data = []
                for s in all_statements:
                    period_label = ""
                    if s.current_fiscal_year_end_date and s.type_of_current_period:
                        fy = s.current_fiscal_year_end_date.strftime("%Y")
                        period_label = f"{fy} {s.type_of_current_period}"

                    chart_data.append({
                        "æœŸé–“": period_label,
                        "å£²ä¸Šé«˜": s.net_sales,
                        "å–¶æ¥­åˆ©ç›Š": s.operating_profit,
                        "ç´”åˆ©ç›Š": s.profit,
                    })

                chart_df = pd.DataFrame(chart_data)

                if not chart_df.empty and chart_df["æœŸé–“"].any():
                    fig = go.Figure()
                    fig.add_trace(go.Bar(
                        x=chart_df["æœŸé–“"], y=chart_df["å£²ä¸Šé«˜"],
                        name="å£²ä¸Šé«˜", marker_color="#667eea",
                    ))
                    fig.add_trace(go.Scatter(
                        x=chart_df["æœŸé–“"], y=chart_df["å–¶æ¥­åˆ©ç›Š"],
                        name="å–¶æ¥­åˆ©ç›Š", mode="lines+markers",
                        line=dict(color="#e74c3c", width=3),
                        yaxis="y2",
                    ))
                    fig.add_trace(go.Scatter(
                        x=chart_df["æœŸé–“"], y=chart_df["ç´”åˆ©ç›Š"],
                        name="ç´”åˆ©ç›Š", mode="lines+markers",
                        line=dict(color="#2ecc71", width=2, dash="dot"),
                        yaxis="y2",
                    ))
                    fig.update_layout(
                        height=350,
                        margin=dict(l=20, r=20, t=30, b=20),
                        yaxis=dict(title="å£²ä¸Šé«˜", side="left"),
                        yaxis2=dict(title="åˆ©ç›Š", overlaying="y", side="right"),
                        legend=dict(orientation="h", y=-0.15),
                        hovermode="x unified",
                    )
                    st.plotly_chart(fig, use_container_width=True)

                # å‰Q/å‰Yæ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«
                analyzer = FinancialAnalyzer()
                yoy = analyzer.compare_year_over_year(selected_code)
                qoq = analyzer.compare_quarter_over_quarter(selected_code)

                comparison_data = {
                    "æŒ‡æ¨™": ["å£²ä¸Šé«˜", "å–¶æ¥­åˆ©ç›Š", "çµŒå¸¸åˆ©ç›Š", "ç´”åˆ©ç›Š"],
                    "å‰å¹´åŒæœŸæ¯”(YoY)": [
                        f"{yoy.get('yoy_net_sales', '-'):+.1f}%" if yoy.get("yoy_net_sales") is not None else "-",
                        f"{yoy.get('yoy_operating_profit', '-'):+.1f}%" if yoy.get("yoy_operating_profit") is not None else "-",
                        f"{yoy.get('yoy_ordinary_profit', '-'):+.1f}%" if yoy.get("yoy_ordinary_profit") is not None else "-",
                        f"{yoy.get('yoy_profit', '-'):+.1f}%" if yoy.get("yoy_profit") is not None else "-",
                    ],
                    "å‰å››åŠæœŸæ¯”(QoQ)": [
                        f"{qoq.get('qoq_net_sales', '-'):+.1f}%" if qoq.get("qoq_net_sales") is not None else "-",
                        f"{qoq.get('qoq_operating_profit', '-'):+.1f}%" if qoq.get("qoq_operating_profit") is not None else "-",
                        f"{qoq.get('qoq_ordinary_profit', '-'):+.1f}%" if qoq.get("qoq_ordinary_profit") is not None else "-",
                        f"{qoq.get('qoq_profit', '-'):+.1f}%" if qoq.get("qoq_profit") is not None else "-",
                    ],
                }
                st.dataframe(pd.DataFrame(comparison_data), width="stretch", hide_index=True)

                # ã‚·ã‚°ãƒŠãƒ«
                signals = analyzer.detect_signals(selected_code)
                if signals:
                    st.subheader("âš¡ æ¤œå‡ºã‚·ã‚°ãƒŠãƒ«")
                    for sig in signals:
                        st.markdown(f"- {sig}")
            else:
                st.info("æ±ºç®—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        # â”€â”€ å³ã‚«ãƒ©ãƒ : AIåˆ†æçµæœ â”€â”€â”€
        with detail_col2:
            st.subheader("ğŸ¤– AIåˆ†æçµæœ")
            session = get_session()
            try:
                ai_result = (
                    session.query(AIAnalysisResult)
                    .filter_by(code=selected_code)
                    .order_by(AIAnalysisResult.analyzed_at.desc())
                    .first()
                )
                if ai_result:
                    session.expunge(ai_result)
            finally:
                session.close()

            if ai_result and ai_result.summary:
                # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆè¡¨ç¤º
                sentiment_emoji = {
                    "positive": "ğŸŸ¢ ãƒã‚¸ãƒ†ã‚£ãƒ–",
                    "negative": "ğŸ”´ ãƒã‚¬ãƒ†ã‚£ãƒ–",
                    "neutral": "ğŸŸ¡ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«",
                }
                st.markdown(f"**ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ:** {sentiment_emoji.get(ai_result.sentiment, 'â“')}")

                st.markdown("**ğŸ“ è¦ç´„:**")
                st.markdown(ai_result.summary)

                # æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ
                try:
                    key_points = json.loads(ai_result.key_points) if ai_result.key_points else []
                except json.JSONDecodeError:
                    key_points = []
                if key_points:
                    st.markdown("**ğŸ”‘ æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ:**")
                    for kp in key_points:
                        st.markdown(f"- {kp}")

                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                try:
                    keywords = json.loads(ai_result.keywords) if ai_result.keywords else []
                except json.JSONDecodeError:
                    keywords = []
                if keywords:
                    st.markdown("**ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                    # ã‚¿ã‚°é¢¨ã«æ¨ªä¸¦ã³è¡¨ç¤º
                    tags_html = " ".join(
                        f'<span style="background:#667eea;color:white;padding:2px 8px;border-radius:10px;margin:2px;display:inline-block;font-size:12px">{kw}</span>'
                        for kw in keywords
                    )
                    st.markdown(tags_html, unsafe_allow_html=True)

                # ã‚·ã‚°ãƒŠãƒ«ãƒ¯ãƒ¼ãƒ‰
                try:
                    signal_words = json.loads(ai_result.signal_words) if ai_result.signal_words else []
                except json.JSONDecodeError:
                    signal_words = []
                if signal_words:
                    st.markdown("**âš¡ ã‚·ã‚°ãƒŠãƒ«ãƒ¯ãƒ¼ãƒ‰:**")
                    for sw in signal_words:
                        st.markdown(f"- {sw}")

                st.caption(f"åˆ†æãƒ¢ãƒ‡ãƒ«: {ai_result.model_used} | åˆ†ææ—¥æ™‚: {ai_result.analyzed_at}")
            else:
                st.info("AIåˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰AIåˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

            # TDneté–‹ç¤ºæƒ…å ±ï¼ˆPDFï¼‰
            st.subheader("ğŸ“„ é–‹ç¤ºè³‡æ–™")
            session = get_session()
            try:
                tdnet_docs = (
                    session.query(TDnetDisclosure)
                    .filter(
                        TDnetDisclosure.code == selected_code,
                        TDnetDisclosure.disclosed_date == dt,
                    )
                    .all()
                )
                if tdnet_docs:
                    for doc in tdnet_docs:
                        with st.expander(doc.title or "æ›¸é¡"):
                            if doc.document_url:
                                st.markdown(f"[ğŸ“„ æ›¸é¡ã‚’é–‹ã]({doc.document_url})")
                            if doc.pdf_local_path:
                                st.caption(f"ãƒ­ãƒ¼ã‚«ãƒ«: {doc.pdf_local_path}")
                else:
                    st.info("TDneté–‹ç¤ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            finally:
                session.close()
else:
    st.info("å¯¾è±¡æ—¥ã®æ±ºç®—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã—ã¦ãã ã•ã„ã€‚")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: AIåˆ†æã‚µãƒãƒªãƒ¼ä¸€è¦§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown('<div class="section-header">ğŸ¤– AIåˆ†æã‚µãƒãƒªãƒ¼ä¸€è¦§</div>', unsafe_allow_html=True)

session = get_session()
try:
    ai_results_all = (
        session.query(AIAnalysisResult, Stock.name)
        .outerjoin(Stock, AIAnalysisResult.code == Stock.code)
        .filter(AIAnalysisResult.disclosed_date == dt)
        .all()
    )
finally:
    session.close()

if ai_results_all:
    ai_rows = []
    for ai, name in ai_results_all:
        try:
            keywords = json.loads(ai.keywords) if ai.keywords else []
        except json.JSONDecodeError:
            keywords = []

        ai_rows.append({
            "ã‚³ãƒ¼ãƒ‰": ai.code,
            "éŠ˜æŸ„å": name or "",
            "ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ": ai.sentiment or "",
            "è¦ç´„": (ai.summary or "")[:100] + "..." if ai.summary and len(ai.summary) > 100 else (ai.summary or ""),
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ", ".join(keywords[:5]) if keywords else "",
        })

    ai_df = pd.DataFrame(ai_rows)
    st.dataframe(ai_df, width="stretch", hide_index=True)
else:
    st.info("AIåˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ•ãƒƒã‚¿ãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.divider()
st.caption(
    "KessanView â€” æ±ºç®—åˆ†æè£œåŠ©ãƒ„ãƒ¼ãƒ« | "
    "ãƒ‡ãƒ¼ã‚¿: J-Quants API / TDnet WEB-API | "
    "AI: Google Gemini"
)
